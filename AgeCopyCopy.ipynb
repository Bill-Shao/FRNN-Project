{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder_name = 'TrainFiles/AgeChange/FourChange'\n",
    "testset_folder_name_W = 'TestFiles/White'\n",
    "testset_folder_name_B = 'TestFiles/Black'\n",
    "\n",
    "TRAIN_TEST_SPLIT = 0.7\n",
    "IM_WIDTH = IM_HEIGHT = 198\n",
    "\n",
    "dataset_dict = {\n",
    "    'race_id': {\n",
    "        0: 'white', \n",
    "        1: 'black', \n",
    "        2: 'asian', \n",
    "        3: 'indian', \n",
    "        4: 'others'\n",
    "    },\n",
    "    'gender_id': {\n",
    "        0: 'male',\n",
    "        1: 'female'\n",
    "    }\n",
    "}\n",
    "\n",
    "dataset_dict['gender_alias'] = dict((g, i) for i, g in dataset_dict['gender_id'].items())\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_dataset(dataset_path, ext='jpg'):\n",
    "    \"\"\"\n",
    "    Used to extract information about our dataset. It does iterate over all images and return a DataFrame with\n",
    "    the data (age, gender and sex) of all files.\n",
    "    \"\"\"\n",
    "    def parse_info_from_file(path):\n",
    "        \"\"\"\n",
    "        Parse information from a single file\n",
    "        \"\"\"\n",
    "        try:\n",
    "            filename = os.path.split(path)[1]\n",
    "            filename = os.path.splitext(filename)[0]\n",
    "            age, gender, race, _ = filename.split('_')\n",
    "\n",
    "            return int(age)\n",
    "        except Exception as ex:\n",
    "            return None, None, None\n",
    "        \n",
    "    files = glob.glob(os.path.join(dataset_path, \"*.%s\" % ext))\n",
    "    random.shuffle(files)\n",
    "    \n",
    "    records = []\n",
    "    for file in files:\n",
    "        info = parse_info_from_file(file)\n",
    "        records.append(info)\n",
    "        \n",
    "    df = pd.DataFrame(records)\n",
    "    df['file'] = files\n",
    "    df.columns = ['age', 'file']\n",
    "    df = df.dropna()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43</td>\n",
       "      <td>TrainFiles/AgeChange/FourChange/43_0_0_2017010...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>TrainFiles/AgeChange/FourChange/11_0_0_2017011...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>TrainFiles/AgeChange/FourChange/100_1_0_201701...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>TrainFiles/AgeChange/FourChange/25_0_1_2017012...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>TrainFiles/AgeChange/FourChange/5_1_0_20170109...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age                                               file\n",
       "0   43  TrainFiles/AgeChange/FourChange/43_0_0_2017010...\n",
       "1   11  TrainFiles/AgeChange/FourChange/11_0_0_2017011...\n",
       "2  100  TrainFiles/AgeChange/FourChange/100_1_0_201701...\n",
       "3   25  TrainFiles/AgeChange/FourChange/25_0_1_2017012...\n",
       "4    5  TrainFiles/AgeChange/FourChange/5_1_0_20170109..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = parse_dataset(dataset_folder_name)\n",
    "testset_W = parse_dataset(testset_folder_name_W)\n",
    "testset_B = parse_dataset(testset_folder_name_B)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Makes Data Generator For Trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/__init__.py:1467: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "class UtkFaceDataGenerator():\n",
    "    \"\"\"\n",
    "    Data generator for the UTKFace dataset. This class should be used when training our Keras multi-output model.\n",
    "    \"\"\"\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        \n",
    "    def generate_split_indexes(self, SPLIT):\n",
    "        p = np.random.permutation(len(self.df))\n",
    "        train_up_to = int(len(self.df) * SPLIT)\n",
    "        train_idx = p[:train_up_to]\n",
    "        test_idx = p[train_up_to:]\n",
    "\n",
    "        train_up_to = int(train_up_to * SPLIT)\n",
    "        train_idx, valid_idx = train_idx[:train_up_to], train_idx[train_up_to:]\n",
    "        \n",
    "        # converts alias to id\n",
    "        self.max_age = self.df['age'].max()\n",
    "        \n",
    "        return train_idx, valid_idx, test_idx\n",
    "    \n",
    "    def preprocess_image(self, img_path):\n",
    "        \"\"\"\n",
    "        Used to perform some minor preprocessing on the image before inputting into the network.\n",
    "        \"\"\"\n",
    "        im = Image.open(img_path)\n",
    "        im = im.resize((IM_WIDTH, IM_HEIGHT))\n",
    "        im = np.array(im) / 255.0\n",
    "        \n",
    "        return im\n",
    "        \n",
    "    def generate_images(self, image_idx, is_training, batch_size=16):\n",
    "        \"\"\"\n",
    "        Used to generate a batch with images when training/testing/validating our Keras model.\n",
    "        \"\"\"\n",
    "        \n",
    "        # arrays to store our batched data\n",
    "        images, ages = [], []\n",
    "        while True:\n",
    "            for idx in image_idx:\n",
    "                person = self.df.iloc[idx]\n",
    "                \n",
    "                age = person['age']\n",
    "                file = person['file']\n",
    "                \n",
    "                im = self.preprocess_image(file)\n",
    "                ages.append(age / self.max_age)\n",
    "                images.append(im)\n",
    "                \n",
    "                # yielding condition\n",
    "                if len(images) >= batch_size:\n",
    "                    yield np.array(images), [np.array(ages)]\n",
    "                    images, ages = [], []\n",
    "                    \n",
    "            if not is_training:\n",
    "                break\n",
    "                \n",
    "data_generator = UtkFaceDataGenerator(df)\n",
    "train_idx, valid_idx, test_idx = data_generator.generate_split_indexes(TRAIN_TEST_SPLIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generator TestSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DATA_SPLIT = 0\n",
    "#White\n",
    "test_data_generator_W = UtkFaceDataGenerator(testset_W)\n",
    "train_idx_test_W, valid_idx_test_W, test_idx_test_W = test_data_generator_W.generate_split_indexes(TEST_DATA_SPLIT)\n",
    "#Black\n",
    "test_data_generator_B = UtkFaceDataGenerator(testset_B)\n",
    "train_idx_test_B, valid_idx_test_B, test_idx_test_B = test_data_generator_B.generate_split_indexes(TEST_DATA_SPLIT)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Making Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Input\n",
    "import tensorflow as tf\n",
    "\n",
    "class UtkMultiOutputModel():\n",
    "    \"\"\"\n",
    "    Used to generate our multi-output model. This CNN contains three branches, one for age, other for \n",
    "    sex and another for race. Each branch contains a sequence of Convolutional Layers that is defined\n",
    "    on the make_default_hidden_layers method.\n",
    "    \"\"\"\n",
    "    def make_default_hidden_layers(self, inputs):\n",
    "        \"\"\"\n",
    "        Used to generate a default set of hidden layers. The structure used in this network is defined as:\n",
    "        \n",
    "        Conv2D -> BatchNormalization -> Pooling -> Dropout\n",
    "        \"\"\"\n",
    "        x = Conv2D(16, (3, 3), padding=\"same\")(inputs)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=-1)(x)\n",
    "        x = MaxPooling2D(pool_size=(3, 3))(x)\n",
    "        x = Dropout(0.25)(x)\n",
    "\n",
    "        x = Conv2D(32, (3, 3), padding=\"same\")(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=-1)(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "        x = Dropout(0.25)(x)\n",
    "\n",
    "        x = Conv2D(32, (3, 3), padding=\"same\")(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=-1)(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "        x = Dropout(0.25)(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def build_race_branch(self, inputs, num_races):\n",
    "        \"\"\"\n",
    "        Used to build the race branch of our face recognition network.\n",
    "        This branch is composed of three Conv -> BN -> Pool -> Dropout blocks, \n",
    "        followed by the Dense output layer.\n",
    "        \"\"\"\n",
    "        x = self.make_default_hidden_layers(inputs)\n",
    "\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(128)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(num_races)(x)\n",
    "        x = Activation(\"softmax\", name=\"race_output\")(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def build_gender_branch(self, inputs, num_genders=2):\n",
    "        \"\"\"\n",
    "        Used to build the gender branch of our face recognition network.\n",
    "        This branch is composed of three Conv -> BN -> Pool -> Dropout blocks, \n",
    "        followed by the Dense output layer.\n",
    "        \"\"\"\n",
    "        x = Lambda(lambda c: tf.image.rgb_to_grayscale(c))(inputs)\n",
    "\n",
    "        x = self.make_default_hidden_layers(inputs)\n",
    "\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(128)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(num_genders)(x)\n",
    "        x = Activation(\"sigmoid\", name=\"gender_output\")(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def build_age_branch(self, inputs):   \n",
    "        \"\"\"\n",
    "        Used to build the age branch of our face recognition network.\n",
    "        This branch is composed of three Conv -> BN -> Pool -> Dropout blocks, \n",
    "        followed by the Dense output layer.\n",
    "\n",
    "        \"\"\"\n",
    "        x = self.make_default_hidden_layers(inputs)\n",
    "\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(128)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(1)(x)\n",
    "        x = Activation(\"linear\", name=\"age_output\")(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def assemble_full_model(self, width, height):\n",
    "        \"\"\"\n",
    "        Used to assemble our multi-output model CNN.\n",
    "        \"\"\"\n",
    "        input_shape = (height, width, 3)\n",
    "\n",
    "        inputs = Input(shape=input_shape)\n",
    "\n",
    "        age_branch = self.build_age_branch(inputs)\n",
    "\n",
    "        model = Model(inputs=inputs,\n",
    "                     outputs = [age_branch],\n",
    "                     name=\"face_net\")\n",
    "\n",
    "        return model\n",
    "    \n",
    "model = UtkMultiOutputModel().assemble_full_model(IM_WIDTH, IM_HEIGHT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"%matplotlib inline\\n\\nfrom keras.utils import plot_model\\nimport matplotlib.image as mpimg\\nimport matplotlib.pyplot as plt\\n\\nplot_model(model, to_file='model.png')\\nimg = mpimg.imread('model.png')\\n\\nplt.figure(figsize=(40, 30))\\nplt.imshow(img)\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''%matplotlib inline\n",
    "\n",
    "from keras.utils import plot_model\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plot_model(model, to_file='model.png')\n",
    "img = mpimg.imread('model.png')\n",
    "\n",
    "plt.figure(figsize=(40, 30))\n",
    "plt.imshow(img)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "2206\n",
      "68\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "init_lr = 1e-4\n",
    "epochs = 100\n",
    "\n",
    "opt = Adam(lr=init_lr, decay=init_lr / epochs)\n",
    "\n",
    "model.compile(optimizer=opt, \n",
    "              loss={\n",
    "                  'age_output': 'mse'},\n",
    "              loss_weights={ \n",
    "                  'age_output': 4.},\n",
    "              metrics={\n",
    "                  'age_output': 'mae'})\n",
    "\n",
    "valid_batch_size = 32\n",
    "print(len(valid_idx))\n",
    "print(len(valid_idx)//valid_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's train our model with a batch size of 32 for both valid and train sets. We will be using a ModelCheckpoint callback in order to save the model on disk at the end of each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Epoch 1/100\n",
      "160/160 [==============================] - 20s 123ms/step - loss: 14.2040 - mean_absolute_error: 1.4659 - val_loss: 6.0453 - val_mean_absolute_error: 0.9496\n",
      "Epoch 2/100\n",
      "160/160 [==============================] - 13s 82ms/step - loss: 10.0921 - mean_absolute_error: 1.2419 - val_loss: 11.9339 - val_mean_absolute_error: 1.2423\n",
      "Epoch 3/100\n",
      "160/160 [==============================] - 14s 85ms/step - loss: 7.8839 - mean_absolute_error: 1.0879 - val_loss: 28.8032 - val_mean_absolute_error: 1.8186\n",
      "Epoch 4/100\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 6.5794 - mean_absolute_error: 1.0035 - val_loss: 93.9610 - val_mean_absolute_error: 3.1461\n",
      "Epoch 5/100\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 6.1284 - mean_absolute_error: 0.9566 - val_loss: 154.8302 - val_mean_absolute_error: 4.0734\n",
      "Epoch 6/100\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 5.4236 - mean_absolute_error: 0.8887 - val_loss: 184.3596 - val_mean_absolute_error: 4.5874\n",
      "Epoch 7/100\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 4.7234 - mean_absolute_error: 0.8340 - val_loss: 544.9134 - val_mean_absolute_error: 8.3676\n",
      "Epoch 8/100\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 4.1621 - mean_absolute_error: 0.7779 - val_loss: 520.8963 - val_mean_absolute_error: 8.1286\n",
      "Epoch 9/100\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 3.8581 - mean_absolute_error: 0.7443 - val_loss: 176.9943 - val_mean_absolute_error: 4.6313\n",
      "Epoch 10/100\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 3.4212 - mean_absolute_error: 0.7072 - val_loss: 151.9592 - val_mean_absolute_error: 4.1593\n",
      "Epoch 11/100\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 3.1397 - mean_absolute_error: 0.6676 - val_loss: 145.8037 - val_mean_absolute_error: 4.1138\n",
      "Epoch 12/100\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 2.8891 - mean_absolute_error: 0.6484 - val_loss: 132.5288 - val_mean_absolute_error: 3.8365\n",
      "Epoch 13/100\n",
      "160/160 [==============================] - 14s 85ms/step - loss: 2.6181 - mean_absolute_error: 0.6139 - val_loss: 113.3184 - val_mean_absolute_error: 3.4482\n",
      "Epoch 14/100\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 2.4136 - mean_absolute_error: 0.5871 - val_loss: 112.6097 - val_mean_absolute_error: 3.4941\n",
      "Epoch 15/100\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 2.0920 - mean_absolute_error: 0.5461 - val_loss: 94.3212 - val_mean_absolute_error: 3.0514\n",
      "Epoch 16/100\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 1.8875 - mean_absolute_error: 0.5170 - val_loss: 91.4579 - val_mean_absolute_error: 3.0275\n",
      "Epoch 17/100\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 1.6713 - mean_absolute_error: 0.4865 - val_loss: 96.7693 - val_mean_absolute_error: 3.1452\n",
      "Epoch 18/100\n",
      "160/160 [==============================] - 14s 85ms/step - loss: 1.5512 - mean_absolute_error: 0.4675 - val_loss: 86.8545 - val_mean_absolute_error: 2.9522\n",
      "Epoch 19/100\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 1.3568 - mean_absolute_error: 0.4400 - val_loss: 87.0639 - val_mean_absolute_error: 2.9790\n",
      "Epoch 20/100\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 1.2183 - mean_absolute_error: 0.4210 - val_loss: 139.1863 - val_mean_absolute_error: 3.5278\n",
      "Epoch 21/100\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 1.1035 - mean_absolute_error: 0.3927 - val_loss: 136.7002 - val_mean_absolute_error: 3.0063\n",
      "Epoch 22/100\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 1.0001 - mean_absolute_error: 0.3743 - val_loss: 108.6646 - val_mean_absolute_error: 2.6858\n",
      "Epoch 23/100\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.8689 - mean_absolute_error: 0.3529 - val_loss: 62.0185 - val_mean_absolute_error: 2.0662\n",
      "Epoch 24/100\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.7703 - mean_absolute_error: 0.3319 - val_loss: 39.7882 - val_mean_absolute_error: 1.5985\n",
      "Epoch 25/100\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.7218 - mean_absolute_error: 0.3156 - val_loss: 41.4269 - val_mean_absolute_error: 1.5973\n",
      "Epoch 26/100\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.6232 - mean_absolute_error: 0.2983 - val_loss: 38.1190 - val_mean_absolute_error: 1.5153\n",
      "Epoch 27/100\n",
      "160/160 [==============================] - 14s 85ms/step - loss: 0.5377 - mean_absolute_error: 0.2780 - val_loss: 38.2888 - val_mean_absolute_error: 1.5101\n",
      "Epoch 28/100\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.4597 - mean_absolute_error: 0.2595 - val_loss: 35.3908 - val_mean_absolute_error: 1.4470\n",
      "Epoch 29/100\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.4186 - mean_absolute_error: 0.2463 - val_loss: 35.9644 - val_mean_absolute_error: 1.4840\n",
      "Epoch 30/100\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.3807 - mean_absolute_error: 0.2319 - val_loss: 30.4858 - val_mean_absolute_error: 1.2862\n",
      "Epoch 31/100\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.3156 - mean_absolute_error: 0.2139 - val_loss: 29.4288 - val_mean_absolute_error: 1.2820\n",
      "Epoch 32/100\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.2838 - mean_absolute_error: 0.2035 - val_loss: 26.1695 - val_mean_absolute_error: 1.1787\n",
      "Epoch 33/100\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.2411 - mean_absolute_error: 0.1899 - val_loss: 23.5857 - val_mean_absolute_error: 1.0949\n",
      "Epoch 34/100\n",
      "160/160 [==============================] - 13s 82ms/step - loss: 0.2246 - mean_absolute_error: 0.1818 - val_loss: 23.1526 - val_mean_absolute_error: 1.0709\n",
      "Epoch 35/100\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.2020 - mean_absolute_error: 0.1715 - val_loss: 23.0794 - val_mean_absolute_error: 1.0639\n",
      "Epoch 36/100\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.1717 - mean_absolute_error: 0.1598 - val_loss: 23.5818 - val_mean_absolute_error: 1.0730\n",
      "Epoch 37/100\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.1568 - mean_absolute_error: 0.1533 - val_loss: 23.6205 - val_mean_absolute_error: 1.0638\n",
      "Epoch 38/100\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.1429 - mean_absolute_error: 0.1467 - val_loss: 21.8069 - val_mean_absolute_error: 1.0025\n",
      "Epoch 39/100\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.1288 - mean_absolute_error: 0.1388 - val_loss: 20.1307 - val_mean_absolute_error: 0.9449\n",
      "Epoch 40/100\n",
      "160/160 [==============================] - 14s 86ms/step - loss: 0.1146 - mean_absolute_error: 0.1320 - val_loss: 18.7446 - val_mean_absolute_error: 0.8897\n",
      "Epoch 41/100\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.1099 - mean_absolute_error: 0.1290 - val_loss: 19.0736 - val_mean_absolute_error: 0.8890\n",
      "Epoch 42/100\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.0979 - mean_absolute_error: 0.1223 - val_loss: 16.6608 - val_mean_absolute_error: 0.8162\n",
      "Epoch 43/100\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.0960 - mean_absolute_error: 0.1216 - val_loss: 14.9290 - val_mean_absolute_error: 0.7428\n",
      "Epoch 44/100\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.0871 - mean_absolute_error: 0.1154 - val_loss: 13.3888 - val_mean_absolute_error: 0.6929\n",
      "Epoch 45/100\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.0840 - mean_absolute_error: 0.1137 - val_loss: 11.3913 - val_mean_absolute_error: 0.6209\n",
      "Epoch 46/100\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.0814 - mean_absolute_error: 0.1111 - val_loss: 8.4487 - val_mean_absolute_error: 0.5102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/100\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.0767 - mean_absolute_error: 0.1085 - val_loss: 9.5227 - val_mean_absolute_error: 0.5453\n",
      "Epoch 48/100\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.0750 - mean_absolute_error: 0.1069 - val_loss: 8.5806 - val_mean_absolute_error: 0.5165\n",
      "Epoch 49/100\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.0702 - mean_absolute_error: 0.1035 - val_loss: 5.9974 - val_mean_absolute_error: 0.4269\n",
      "Epoch 50/100\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.0704 - mean_absolute_error: 0.1035 - val_loss: 6.1288 - val_mean_absolute_error: 0.4363\n",
      "Epoch 51/100\n",
      "160/160 [==============================] - 14s 85ms/step - loss: 0.0697 - mean_absolute_error: 0.1033 - val_loss: 6.4668 - val_mean_absolute_error: 0.4483\n",
      "Epoch 52/100\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.0667 - mean_absolute_error: 0.1006 - val_loss: 9.8695 - val_mean_absolute_error: 0.5627\n",
      "Epoch 53/100\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.0668 - mean_absolute_error: 0.1006 - val_loss: 2.8477 - val_mean_absolute_error: 0.2834\n",
      "Epoch 54/100\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.0648 - mean_absolute_error: 0.0994 - val_loss: 4.7413 - val_mean_absolute_error: 0.3534\n",
      "Epoch 55/100\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.0627 - mean_absolute_error: 0.0975 - val_loss: 4.6456 - val_mean_absolute_error: 0.3580\n",
      "Epoch 56/100\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.0638 - mean_absolute_error: 0.0990 - val_loss: 3.3372 - val_mean_absolute_error: 0.2979\n",
      "Epoch 57/100\n",
      "160/160 [==============================] - 14s 84ms/step - loss: 0.0619 - mean_absolute_error: 0.0974 - val_loss: 3.3862 - val_mean_absolute_error: 0.2927\n",
      "Epoch 58/100\n",
      "160/160 [==============================] - 14s 85ms/step - loss: 0.0610 - mean_absolute_error: 0.0966 - val_loss: 1.8846 - val_mean_absolute_error: 0.2237\n",
      "Epoch 59/100\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.0587 - mean_absolute_error: 0.0945 - val_loss: 2.1686 - val_mean_absolute_error: 0.2350\n",
      "Epoch 60/100\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.0595 - mean_absolute_error: 0.0950 - val_loss: 1.9134 - val_mean_absolute_error: 0.2223\n",
      "Epoch 61/100\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.0582 - mean_absolute_error: 0.0938 - val_loss: 2.2470 - val_mean_absolute_error: 0.2356\n",
      "Epoch 62/100\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.0570 - mean_absolute_error: 0.0930 - val_loss: 2.2439 - val_mean_absolute_error: 0.2291\n",
      "Epoch 63/100\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.0557 - mean_absolute_error: 0.0920 - val_loss: 1.5725 - val_mean_absolute_error: 0.1966\n",
      "Epoch 64/100\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.0542 - mean_absolute_error: 0.0905 - val_loss: 1.8832 - val_mean_absolute_error: 0.2042\n",
      "Epoch 65/100\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.0548 - mean_absolute_error: 0.0908 - val_loss: 1.4295 - val_mean_absolute_error: 0.1910\n",
      "Epoch 66/100\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.0542 - mean_absolute_error: 0.0905 - val_loss: 0.8935 - val_mean_absolute_error: 0.1585\n",
      "Epoch 67/100\n",
      "160/160 [==============================] - 14s 86ms/step - loss: 0.0528 - mean_absolute_error: 0.0901 - val_loss: 0.6558 - val_mean_absolute_error: 0.1421\n",
      "Epoch 68/100\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.0528 - mean_absolute_error: 0.0889 - val_loss: 0.7490 - val_mean_absolute_error: 0.1441\n",
      "Epoch 69/100\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.0508 - mean_absolute_error: 0.0880 - val_loss: 0.5853 - val_mean_absolute_error: 0.1296\n",
      "Epoch 70/100\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.0508 - mean_absolute_error: 0.0873 - val_loss: 1.0691 - val_mean_absolute_error: 0.1581\n",
      "Epoch 71/100\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.0506 - mean_absolute_error: 0.0873 - val_loss: 0.8406 - val_mean_absolute_error: 0.1437\n",
      "Epoch 72/100\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.0495 - mean_absolute_error: 0.0866 - val_loss: 0.6695 - val_mean_absolute_error: 0.1314\n",
      "Epoch 73/100\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.0485 - mean_absolute_error: 0.0851 - val_loss: 0.6834 - val_mean_absolute_error: 0.1273\n",
      "Epoch 74/100\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.0479 - mean_absolute_error: 0.0845 - val_loss: 0.6307 - val_mean_absolute_error: 0.1294\n",
      "Epoch 75/100\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.0485 - mean_absolute_error: 0.0857 - val_loss: 0.6635 - val_mean_absolute_error: 0.1315\n",
      "Epoch 76/100\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.0468 - mean_absolute_error: 0.0844 - val_loss: 0.4234 - val_mean_absolute_error: 0.1084\n",
      "Epoch 77/100\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.0458 - mean_absolute_error: 0.0835 - val_loss: 0.5634 - val_mean_absolute_error: 0.1157\n",
      "Epoch 78/100\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.0450 - mean_absolute_error: 0.0828 - val_loss: 0.8166 - val_mean_absolute_error: 0.1776\n",
      "Epoch 79/100\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.0457 - mean_absolute_error: 0.0831 - val_loss: 0.3044 - val_mean_absolute_error: 0.1037\n",
      "Epoch 80/100\n",
      "160/160 [==============================] - 14s 86ms/step - loss: 0.0444 - mean_absolute_error: 0.0821 - val_loss: 0.5253 - val_mean_absolute_error: 0.1293\n",
      "Epoch 81/100\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.0468 - mean_absolute_error: 0.0824 - val_loss: 5.6766 - val_mean_absolute_error: 0.3298\n",
      "Epoch 82/100\n",
      "160/160 [==============================] - 13s 82ms/step - loss: 0.0460 - mean_absolute_error: 0.0809 - val_loss: 1.5358 - val_mean_absolute_error: 0.1464\n",
      "Epoch 83/100\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.0423 - mean_absolute_error: 0.0797 - val_loss: 1.0993 - val_mean_absolute_error: 0.1458\n",
      "Epoch 84/100\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.0421 - mean_absolute_error: 0.0800 - val_loss: 0.8475 - val_mean_absolute_error: 0.1306\n",
      "Epoch 85/100\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.0422 - mean_absolute_error: 0.0793 - val_loss: 0.9275 - val_mean_absolute_error: 0.1368\n",
      "Epoch 86/100\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.0394 - mean_absolute_error: 0.0775 - val_loss: 0.9679 - val_mean_absolute_error: 0.1404\n",
      "Epoch 87/100\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.0405 - mean_absolute_error: 0.0778 - val_loss: 0.7800 - val_mean_absolute_error: 0.1212\n",
      "Epoch 88/100\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.0407 - mean_absolute_error: 0.0784 - val_loss: 1.1123 - val_mean_absolute_error: 0.1363\n",
      "Epoch 89/100\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.0419 - mean_absolute_error: 0.0789 - val_loss: 5.4299 - val_mean_absolute_error: 0.3379\n",
      "Epoch 90/100\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.0412 - mean_absolute_error: 0.0792 - val_loss: 2.2216 - val_mean_absolute_error: 0.1773\n",
      "Epoch 91/100\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.0392 - mean_absolute_error: 0.0773 - val_loss: 1.9137 - val_mean_absolute_error: 0.1613\n",
      "Epoch 92/100\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.0382 - mean_absolute_error: 0.0762 - val_loss: 1.4329 - val_mean_absolute_error: 0.1485\n",
      "Epoch 93/100\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.0395 - mean_absolute_error: 0.0773 - val_loss: 1.0423 - val_mean_absolute_error: 0.1366\n",
      "Epoch 94/100\n",
      "160/160 [==============================] - 14s 85ms/step - loss: 0.0385 - mean_absolute_error: 0.0769 - val_loss: 1.1924 - val_mean_absolute_error: 0.1378\n",
      "Epoch 95/100\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.0375 - mean_absolute_error: 0.0756 - val_loss: 0.9910 - val_mean_absolute_error: 0.1323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/100\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.0370 - mean_absolute_error: 0.0746 - val_loss: 0.7266 - val_mean_absolute_error: 0.1225\n",
      "Epoch 97/100\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.0369 - mean_absolute_error: 0.0751 - val_loss: 0.7501 - val_mean_absolute_error: 0.1213\n",
      "Epoch 98/100\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.0359 - mean_absolute_error: 0.0735 - val_loss: 0.9084 - val_mean_absolute_error: 0.1262\n",
      "Epoch 99/100\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.0355 - mean_absolute_error: 0.0742 - val_loss: 0.4970 - val_mean_absolute_error: 0.1116\n",
      "Epoch 100/100\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.0354 - mean_absolute_error: 0.0734 - val_loss: 0.4643 - val_mean_absolute_error: 0.1048\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "batch_size = 32\n",
    "valid_batch_size = 32\n",
    "train_gen = data_generator.generate_images(train_idx, is_training=True, batch_size=batch_size)\n",
    "valid_gen = data_generator.generate_images(valid_idx, is_training=True, batch_size=valid_batch_size)\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\"./model_checkpoint\", monitor='val_loss')\n",
    "]\n",
    "\n",
    "history = model.fit_generator(train_gen,\n",
    "                    steps_per_epoch=len(train_idx)//batch_size,\n",
    "                    epochs=epochs,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=valid_gen,\n",
    "                    validation_steps=len(valid_idx)//valid_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import explained_variance_score\n",
    "test_batch_size = 128\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WHITE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score for age:  -4.883476167077703\n",
      "Deviance Score for age: -4.883354119204407\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_data_generator_W.generate_images(test_idx_test_W, is_training=False, batch_size=test_batch_size)\n",
    "age_pred = model.predict_generator(test_generator, steps=len(test_idx_test_W)//test_batch_size)\n",
    "\n",
    "\n",
    "\n",
    "test_generator = test_data_generator_W.generate_images(test_idx_test_W, is_training=False, batch_size=test_batch_size)\n",
    "samples = 0\n",
    "images, age_true = [], []\n",
    "for test_batch in test_generator:\n",
    "    image = test_batch[0]\n",
    "    labels = test_batch[1]\n",
    "    \n",
    "    images.extend(image)\n",
    "    age_true.extend(labels[0])\n",
    "\n",
    "age_true = np.array(age_true)\n",
    "\n",
    "age_true = age_true * data_generator.max_age\n",
    "age_pred = age_pred * data_generator.max_age\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "'''cr_age = classification_report(age_true, age_pred, target_names=dataset_dict['gender_alias'].keys())\n",
    "print(cr_age)'''\n",
    "print('R2 score for age: ', r2_score(age_true, age_pred))\n",
    "print('Deviance Score for age:', explained_variance_score(age_true, age_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLACK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score for age:  -16.41406893345584\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_data_generator_B.generate_images(test_idx_test_B, is_training=False, batch_size=test_batch_size)\n",
    "age_pred = model.predict_generator(test_generator, steps=len(test_idx_test_B)//test_batch_size)\n",
    "\n",
    "\n",
    "\n",
    "test_generator = test_data_generator_B.generate_images(test_idx_test_B, is_training=False, batch_size=test_batch_size)\n",
    "samples = 0\n",
    "images, age_true = [], []\n",
    "for test_batch in test_generator:\n",
    "    image = test_batch[0]\n",
    "    labels = test_batch[1]\n",
    "    \n",
    "    images.extend(image)\n",
    "    age_true.extend(labels[0])\n",
    "\n",
    "age_true = np.array(age_true)\n",
    "\n",
    "age_true = age_true * (data_generator.max_age)\n",
    "age_pred = age_pred * (data_generator.max_age)\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "'''cr_age = classification_report(age_true, age_pred, target_names=dataset_dict['gender_alias'].keys())\n",
    "print(cr_age)'''\n",
    "print('R2 score for age: ', r2_score(age_true, age_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 33.65656566  43.27272727  69.71717172  38.46464646  78.13131313\n",
      "  31.25252525  37.26262626  37.26262626  36.06060606  31.25252525\n",
      "  56.49494949  56.49494949  34.85858586  37.26262626  40.86868687\n",
      "  33.65656566  33.65656566  42.07070707  33.65656566  54.09090909\n",
      "  63.70707071  46.87878788  42.07070707  31.25252525  36.06060606\n",
      "   3.60606061  48.08080808  81.73737374  32.45454545  16.82828283\n",
      "  80.53535354  33.65656566  18.03030303  34.85858586   3.60606061\n",
      "  31.25252525 108.18181818  31.25252525  34.85858586  60.1010101\n",
      "  37.26262626  21.63636364  64.90909091   2.4040404   33.65656566\n",
      "  32.45454545  48.08080808  33.65656566  37.26262626  45.67676768\n",
      "  30.05050505  84.14141414  44.47474747  48.08080808  48.08080808\n",
      "  28.84848485  40.86868687  37.26262626  31.25252525  40.86868687\n",
      "  37.26262626  31.25252525  33.65656566  45.67676768  33.65656566\n",
      "  37.26262626  42.07070707  32.45454545  30.05050505  32.45454545\n",
      "  26.44444444  31.25252525  31.25252525  48.08080808  38.46464646\n",
      "  18.03030303   8.41414141  42.07070707  46.87878788  34.85858586\n",
      "  43.27272727  30.05050505  21.63636364  31.25252525  27.64646465\n",
      "  31.25252525  66.11111111  34.85858586  67.31313131  30.05050505\n",
      "  31.25252525  63.70707071  33.65656566  32.45454545  38.46464646\n",
      "  39.66666667  31.25252525  63.70707071  74.52525253  44.47474747\n",
      "  48.08080808  69.71717172   3.60606061  33.65656566  31.25252525\n",
      "  31.25252525  31.25252525  56.49494949  43.27272727  28.84848485\n",
      "  67.31313131  50.48484848   7.21212121  45.67676768  20.43434343\n",
      "  31.25252525   6.01010101  25.24242424  43.27272727  39.66666667\n",
      "  62.50505051  61.3030303   32.45454545  38.46464646  39.66666667\n",
      "  26.44444444  46.87878788  31.25252525  31.25252525  31.25252525\n",
      "  73.32323232  38.46464646  42.07070707  27.64646465  42.07070707\n",
      "  38.46464646  54.09090909  36.06060606  50.48484848  31.25252525\n",
      "  60.1010101   43.27272727  43.27272727  67.31313131   8.41414141\n",
      "  28.84848485  26.44444444  37.26262626  38.46464646  84.14141414\n",
      "  31.25252525  31.25252525  24.04040404  24.04040404  31.25252525\n",
      "   9.61616162  46.87878788  31.25252525  46.87878788  32.45454545\n",
      "  43.27272727  78.13131313  45.67676768  66.11111111  31.25252525\n",
      "  78.13131313  40.86868687  44.47474747  28.84848485  31.25252525\n",
      "  57.6969697   33.65656566   6.01010101  57.6969697   58.8989899\n",
      "  74.52525253 108.18181818  43.27272727  25.24242424  12.02020202\n",
      "  26.44444444  84.14141414  40.86868687  43.27272727  48.08080808\n",
      "  36.06060606  31.25252525  25.24242424  43.27272727  38.46464646\n",
      "   1.2020202   10.81818182  45.67676768  36.06060606  43.27272727\n",
      "  28.84848485  31.25252525  43.27272727  42.07070707  31.25252525\n",
      "  42.07070707  88.94949495  37.26262626  40.86868687  31.25252525\n",
      "  27.64646465  49.28282828  33.65656566  61.3030303   28.84848485\n",
      "  73.32323232  21.63636364  32.45454545  28.84848485  36.06060606\n",
      "  18.03030303 108.18181818  45.67676768  16.82828283  37.26262626\n",
      "  30.05050505   4.80808081  42.07070707   9.61616162  44.47474747\n",
      "  33.65656566  50.48484848  25.24242424  31.25252525  62.50505051\n",
      "  33.65656566  12.02020202  33.65656566  43.27272727  25.24242424\n",
      "  38.46464646  48.08080808  28.84848485  38.46464646  75.72727273\n",
      "  30.05050505  63.70707071  36.06060606  43.27272727  31.25252525\n",
      "  43.27272727  40.86868687  32.45454545  28.84848485  20.43434343\n",
      "  22.83838384  37.26262626  76.92929293  43.27272727  45.67676768\n",
      "  48.08080808  31.25252525  38.46464646  33.65656566  34.85858586\n",
      "  31.25252525  45.67676768  37.26262626  31.25252525  36.06060606\n",
      "  38.46464646  60.1010101   30.05050505   8.41414141  34.85858586\n",
      "  28.84848485  32.45454545  32.45454545  39.66666667  31.25252525\n",
      "  31.25252525   1.2020202   69.71717172  34.85858586  34.85858586\n",
      "  45.67676768  25.24242424  19.23232323  33.65656566  28.84848485\n",
      "  30.05050505  33.65656566  31.25252525  38.46464646  45.67676768\n",
      "  31.25252525  31.25252525  24.04040404  67.31313131  33.65656566\n",
      "  45.67676768  31.25252525  28.84848485  64.90909091  42.07070707\n",
      "  45.67676768  50.48484848  36.06060606  46.87878788  26.44444444\n",
      "  57.6969697   33.65656566  42.07070707  42.07070707  20.43434343\n",
      "  30.05050505  48.08080808  36.06060606  34.85858586  34.85858586\n",
      "  40.86868687  52.88888889  20.43434343  69.71717172  37.26262626\n",
      "  48.08080808  32.45454545  42.07070707  28.84848485  28.84848485\n",
      "  46.87878788  25.24242424  38.46464646  73.32323232  50.48484848\n",
      "  31.25252525  51.68686869  10.81818182  32.45454545  31.25252525\n",
      "  70.91919192  36.06060606  40.86868687  31.25252525  60.1010101\n",
      "  28.84848485  25.24242424  67.31313131  31.25252525  66.11111111\n",
      "  26.44444444  39.66666667  54.09090909  31.25252525  36.06060606\n",
      "  36.06060606  31.25252525  31.25252525  60.1010101   24.04040404\n",
      "  40.86868687  34.85858586  13.22222222  43.27272727  54.09090909\n",
      "  42.07070707  33.65656566  33.65656566  31.25252525  42.07070707\n",
      "  26.44444444  45.67676768  96.16161616  49.28282828  30.05050505\n",
      "  73.32323232  46.87878788  64.90909091  27.64646465  42.07070707\n",
      "  48.08080808  34.85858586  26.44444444  36.06060606  31.25252525\n",
      "  31.25252525  61.3030303   31.25252525  45.67676768  50.48484848\n",
      "  24.04040404  30.05050505  31.25252525  42.07070707  51.68686869\n",
      "  50.48484848  28.84848485  31.25252525  33.65656566  67.31313131\n",
      "  34.85858586  45.67676768  31.25252525  42.07070707  33.65656566\n",
      "  40.86868687  27.64646465  38.46464646  28.84848485  32.45454545\n",
      "  21.63636364  31.25252525  33.65656566  37.26262626  34.85858586\n",
      "  31.25252525  37.26262626  62.50505051  48.08080808  31.25252525\n",
      "  38.46464646  27.64646465  90.15151515  32.45454545   3.60606061\n",
      "  60.1010101   42.07070707  44.47474747  34.85858586   4.80808081\n",
      "  42.07070707  31.25252525  43.27272727   7.21212121  27.64646465\n",
      "  38.46464646  44.47474747  31.25252525  30.05050505   8.41414141\n",
      "  38.46464646  34.85858586  80.53535354  37.26262626  54.09090909\n",
      "  26.44444444  27.64646465  54.09090909  38.46464646  42.07070707\n",
      "  32.45454545  31.25252525  62.50505051  64.90909091  21.63636364\n",
      "  24.04040404  30.05050505  37.26262626  44.47474747  54.09090909\n",
      "  26.44444444   7.21212121  62.50505051  67.31313131  45.67676768\n",
      "  80.53535354  57.6969697   60.1010101   33.65656566  79.33333333\n",
      "  28.84848485  25.24242424  28.84848485  34.85858586  33.65656566\n",
      "  30.05050505  42.07070707  42.07070707  30.05050505  42.07070707\n",
      "  31.25252525  33.65656566  31.25252525  39.66666667  27.64646465\n",
      "  42.07070707  44.47474747  21.63636364  31.25252525 106.97979798\n",
      "  61.3030303   28.84848485  36.06060606  70.91919192  64.90909091\n",
      "  28.84848485  36.06060606  24.04040404  31.25252525  42.07070707\n",
      "  38.46464646  46.87878788  43.27272727  87.74747475  31.25252525\n",
      "  26.44444444  24.04040404  28.84848485  28.84848485  60.1010101\n",
      "  48.08080808  31.25252525  34.85858586  28.84848485  24.04040404\n",
      "  38.46464646  25.24242424  21.63636364  61.3030303   37.26262626\n",
      "  62.50505051  36.06060606  32.45454545  78.13131313  66.11111111\n",
      "  25.24242424  31.25252525  33.65656566  44.47474747  44.47474747\n",
      "  39.66666667  31.25252525  45.67676768  55.29292929  72.12121212\n",
      "  33.65656566  30.05050505  87.74747475  31.25252525  31.25252525\n",
      "  31.25252525  54.09090909  36.06060606  37.26262626  91.35353535\n",
      "  34.85858586  67.31313131  38.46464646  54.09090909  33.65656566\n",
      "  45.67676768  25.24242424  28.84848485  31.25252525  50.48484848\n",
      "  31.25252525  34.85858586  31.25252525  42.07070707  25.24242424\n",
      "  56.49494949  34.85858586  46.87878788  72.12121212  26.44444444\n",
      "  42.07070707  26.44444444  30.05050505  33.65656566  75.72727273\n",
      "  30.05050505  31.25252525  22.83838384  30.05050505  34.85858586\n",
      "  31.25252525  28.84848485  25.24242424  32.45454545  38.46464646\n",
      "  26.44444444  82.93939394  32.45454545  42.07070707  25.24242424\n",
      "  43.27272727  22.83838384 119.          54.09090909  31.25252525\n",
      "   1.2020202   33.65656566  44.47474747  31.25252525  33.65656566\n",
      "  27.64646465  26.44444444  46.87878788  42.07070707  31.25252525\n",
      "  37.26262626  37.26262626  34.85858586  57.6969697   78.13131313\n",
      "  33.65656566  31.25252525  34.85858586  48.08080808  45.67676768\n",
      "  27.64646465  45.67676768  31.25252525  31.25252525  64.90909091\n",
      "  67.31313131  40.86868687  31.25252525  30.05050505  32.45454545\n",
      "  69.71717172  27.64646465  63.70707071  33.65656566  33.65656566\n",
      "  30.05050505  26.44444444  54.09090909  34.85858586  25.24242424\n",
      "  24.04040404  31.25252525  38.46464646  37.26262626  48.08080808\n",
      "  34.85858586  48.08080808  84.14141414   2.4040404   34.85858586\n",
      "  31.25252525  31.25252525  74.52525253  43.27272727  46.87878788\n",
      "  38.46464646   9.61616162  38.46464646  42.07070707  26.44444444\n",
      "  31.25252525  64.90909091  28.84848485  30.05050505  36.06060606\n",
      "  86.54545455  38.46464646  33.65656566  30.05050505  31.25252525\n",
      "  31.25252525  34.85858586  28.84848485  33.65656566  31.25252525\n",
      "  31.25252525  31.25252525  28.84848485  42.07070707  33.65656566\n",
      "  28.84848485  33.65656566  48.08080808  31.25252525  37.26262626\n",
      "  36.06060606  58.8989899   31.25252525  31.25252525  34.85858586\n",
      "  60.1010101   31.25252525  30.05050505  62.50505051  33.65656566\n",
      "   6.01010101  43.27272727  78.13131313  18.03030303  31.25252525\n",
      "  38.46464646  19.23232323  45.67676768  31.25252525  33.65656566\n",
      "  50.48484848  31.25252525  78.13131313  30.05050505  61.3030303\n",
      "  36.06060606  36.06060606  42.07070707  21.63636364  36.06060606\n",
      "  31.25252525  78.13131313  31.25252525   6.01010101  36.06060606\n",
      "  31.25252525  66.11111111  54.09090909  38.46464646  93.75757576\n",
      "  33.65656566  66.11111111  40.86868687  84.14141414  32.45454545\n",
      "  30.05050505  38.46464646  40.86868687  38.46464646  24.04040404\n",
      "  42.07070707  45.67676768  30.05050505  42.07070707  33.65656566\n",
      "  43.27272727  40.86868687  69.71717172  96.16161616  34.85858586\n",
      "  31.25252525  42.07070707  42.07070707   2.4040404   20.43434343\n",
      "  36.06060606  31.25252525  30.05050505  69.71717172  18.03030303\n",
      "  25.24242424  22.83838384  31.25252525  31.25252525  36.06060606\n",
      "  33.65656566  31.25252525  42.07070707  33.65656566  51.68686869\n",
      "   1.2020202   45.67676768  48.08080808  21.63636364  24.04040404\n",
      "  28.84848485  30.05050505  42.07070707  31.25252525  28.84848485\n",
      "  52.88888889  69.71717172  78.13131313  32.45454545  37.26262626\n",
      "  25.24242424  18.03030303  50.48484848]\n",
      "[[ 5.52579689e+01]\n",
      " [ 3.54241295e+01]\n",
      " [ 4.26842270e+01]\n",
      " [ 3.10958805e+01]\n",
      " [ 5.09418068e+01]\n",
      " [ 4.26469040e+01]\n",
      " [ 6.27954979e+01]\n",
      " [ 3.62799377e+01]\n",
      " [ 3.75441017e+01]\n",
      " [ 4.14311790e+01]\n",
      " [ 4.44512291e+01]\n",
      " [ 5.04693565e+01]\n",
      " [ 3.39020157e+01]\n",
      " [ 3.91496086e+01]\n",
      " [ 3.93197098e+01]\n",
      " [ 3.59906387e+01]\n",
      " [ 3.24819717e+01]\n",
      " [ 7.59526520e+01]\n",
      " [ 4.50998726e+01]\n",
      " [ 2.12230034e+01]\n",
      " [ 4.87129822e+01]\n",
      " [ 2.31407181e+02]\n",
      " [ 4.27168884e+01]\n",
      " [ 4.86195259e+01]\n",
      " [ 2.89374523e+01]\n",
      " [ 1.21793747e+01]\n",
      " [ 2.53357925e+01]\n",
      " [ 4.86840363e+01]\n",
      " [ 3.32167969e+01]\n",
      " [ 4.55057678e+01]\n",
      " [ 6.84735107e+01]\n",
      " [ 5.30208855e+01]\n",
      " [ 2.42324390e+01]\n",
      " [ 3.38616295e+01]\n",
      " [ 2.53103161e+01]\n",
      " [ 3.41708450e+01]\n",
      " [ 8.49531860e+01]\n",
      " [ 1.33081802e+02]\n",
      " [ 4.51720848e+01]\n",
      " [ 4.62101326e+01]\n",
      " [ 3.34981422e+01]\n",
      " [ 2.45416832e+01]\n",
      " [ 4.49474831e+01]\n",
      " [ 9.28159809e+00]\n",
      " [ 1.89707581e+02]\n",
      " [ 3.96303635e+01]\n",
      " [ 4.23798218e+01]\n",
      " [ 1.04426323e+02]\n",
      " [ 2.99606743e+01]\n",
      " [ 6.78632736e+01]\n",
      " [ 3.07393532e+01]\n",
      " [ 4.67531281e+01]\n",
      " [ 4.19349861e+01]\n",
      " [ 3.77331429e+01]\n",
      " [ 2.04611954e+02]\n",
      " [ 3.94540596e+01]\n",
      " [ 3.44583282e+01]\n",
      " [ 2.97598667e+01]\n",
      " [ 4.03119583e+01]\n",
      " [ 3.76331749e+01]\n",
      " [ 4.10303383e+01]\n",
      " [ 4.38850784e+01]\n",
      " [ 1.43071762e+02]\n",
      " [ 3.27865562e+01]\n",
      " [ 3.78558235e+01]\n",
      " [ 3.02889519e+01]\n",
      " [ 3.40129204e+01]\n",
      " [ 4.15980186e+01]\n",
      " [ 2.30204487e+01]\n",
      " [ 3.43235359e+01]\n",
      " [ 3.06383114e+01]\n",
      " [ 3.12422657e+01]\n",
      " [ 2.85872765e+01]\n",
      " [ 3.01345482e+01]\n",
      " [ 3.49967766e+01]\n",
      " [ 1.98818550e+01]\n",
      " [ 3.47190704e+01]\n",
      " [ 3.62231102e+01]\n",
      " [ 3.00797367e+01]\n",
      " [ 2.92888527e+01]\n",
      " [ 1.16295456e+02]\n",
      " [ 3.19890041e+01]\n",
      " [ 2.22565575e+01]\n",
      " [ 3.23188438e+01]\n",
      " [ 3.28773384e+01]\n",
      " [ 4.01467590e+01]\n",
      " [ 3.77277069e+01]\n",
      " [ 5.38073654e+01]\n",
      " [ 4.15827637e+01]\n",
      " [ 1.48446136e+02]\n",
      " [ 1.75377426e+01]\n",
      " [ 4.29616776e+01]\n",
      " [ 3.41934319e+01]\n",
      " [ 2.97371120e+01]\n",
      " [ 3.91964226e+01]\n",
      " [ 2.77005920e+01]\n",
      " [ 3.43535652e+01]\n",
      " [ 6.01990242e+01]\n",
      " [ 5.84975433e+01]\n",
      " [ 3.99757195e+01]\n",
      " [ 2.33344406e+02]\n",
      " [ 5.87311974e+01]\n",
      " [ 2.49985313e+01]\n",
      " [ 4.71880684e+01]\n",
      " [ 1.15376228e+02]\n",
      " [ 5.57990379e+01]\n",
      " [ 3.88348694e+01]\n",
      " [ 4.62386475e+01]\n",
      " [ 2.65971165e+01]\n",
      " [ 2.85594788e+01]\n",
      " [ 4.52261772e+01]\n",
      " [ 2.83930893e+01]\n",
      " [ 5.25189819e+02]\n",
      " [ 3.51298637e+01]\n",
      " [ 2.89035187e+01]\n",
      " [ 3.08776760e+01]\n",
      " [ 2.71314583e+01]\n",
      " [ 3.73941650e+01]\n",
      " [ 3.99128914e+01]\n",
      " [ 3.97007523e+01]\n",
      " [ 5.50768471e+01]\n",
      " [ 4.24260368e+01]\n",
      " [ 5.05880165e+01]\n",
      " [ 4.23021202e+01]\n",
      " [ 3.76737175e+01]\n",
      " [ 4.00841141e+01]\n",
      " [ 3.95791473e+01]\n",
      " [ 4.19767685e+01]\n",
      " [ 3.31800652e+01]\n",
      " [ 3.98216934e+01]\n",
      " [ 4.97637405e+01]\n",
      " [ 4.65199471e+01]\n",
      " [ 3.94737701e+01]\n",
      " [ 5.29862785e+01]\n",
      " [ 3.04384995e+01]\n",
      " [ 2.53224678e+01]\n",
      " [ 4.56197586e+01]\n",
      " [ 3.57664108e+01]\n",
      " [ 4.89607353e+01]\n",
      " [ 4.84836006e+01]\n",
      " [ 5.29707260e+01]\n",
      " [ 3.15445518e+01]\n",
      " [ 3.26558495e+01]\n",
      " [ 3.61063690e+01]\n",
      " [ 2.16232548e+01]\n",
      " [ 2.43215046e+01]\n",
      " [ 3.20477676e+01]\n",
      " [ 3.44830017e+01]\n",
      " [ 4.32557335e+01]\n",
      " [ 2.08284637e+02]\n",
      " [ 2.47029076e+01]\n",
      " [ 3.71956635e+01]\n",
      " [ 4.32631264e+01]\n",
      " [ 1.75932121e+01]\n",
      " [ 3.11207523e+01]\n",
      " [ 3.96529350e+01]\n",
      " [ 3.98314095e+01]\n",
      " [ 3.23757782e+01]\n",
      " [ 4.23296967e+01]\n",
      " [ 2.34570732e+01]\n",
      " [ 2.63924046e+01]\n",
      " [ 8.11577759e+01]\n",
      " [ 4.98147736e+01]\n",
      " [ 3.82455940e+01]\n",
      " [ 3.85065231e+01]\n",
      " [ 4.51840820e+01]\n",
      " [ 3.30868874e+01]\n",
      " [ 3.04699554e+01]\n",
      " [ 3.81245766e+01]\n",
      " [ 3.32223625e+01]\n",
      " [ 4.13521423e+01]\n",
      " [ 3.69343224e+01]\n",
      " [ 2.61668186e+01]\n",
      " [ 4.12384758e+01]\n",
      " [ 3.89363098e+01]\n",
      " [ 5.29958687e+01]\n",
      " [ 6.98998032e+01]\n",
      " [ 3.65009499e+01]\n",
      " [ 1.29152725e+02]\n",
      " [ 3.03692074e+01]\n",
      " [ 2.97715836e+01]\n",
      " [ 5.71642723e+01]\n",
      " [ 4.40152969e+01]\n",
      " [ 4.33270340e+01]\n",
      " [ 3.14422112e+01]\n",
      " [ 3.78181610e+01]\n",
      " [ 3.27123032e+01]\n",
      " [ 2.37198391e+01]\n",
      " [ 2.12584515e+01]\n",
      " [ 3.56152306e+01]\n",
      " [ 9.37613201e+00]\n",
      " [ 8.40539360e+00]\n",
      " [ 3.43392525e+01]\n",
      " [ 3.25727882e+01]\n",
      " [ 4.81936836e+01]\n",
      " [ 3.37740974e+01]\n",
      " [ 4.02649498e+01]\n",
      " [ 3.82912331e+01]\n",
      " [ 5.33519058e+01]\n",
      " [ 5.18512230e+01]\n",
      " [ 1.07417336e+02]\n",
      " [ 7.81388474e+01]\n",
      " [ 7.27576218e+01]\n",
      " [ 3.73430214e+01]\n",
      " [ 5.01827850e+01]\n",
      " [ 4.46053734e+01]\n",
      " [ 4.69274979e+01]\n",
      " [ 3.76883240e+01]\n",
      " [ 4.26298218e+01]\n",
      " [ 4.00899467e+01]\n",
      " [-2.49220009e+01]\n",
      " [ 1.45431566e+01]\n",
      " [ 4.40731812e+01]\n",
      " [ 3.56973495e+01]\n",
      " [ 3.11669445e+01]\n",
      " [ 2.19982700e+01]\n",
      " [ 6.01192017e+01]\n",
      " [ 5.55595589e+01]\n",
      " [ 1.69231148e+01]\n",
      " [ 3.84763374e+01]\n",
      " [ 2.16069031e+01]\n",
      " [ 1.17201395e+01]\n",
      " [ 4.69194183e+01]\n",
      " [ 3.23094635e+01]\n",
      " [ 3.88397369e+01]\n",
      " [ 6.56711502e+01]\n",
      " [ 3.76485405e+01]\n",
      " [ 2.23227119e+01]\n",
      " [ 3.73641205e+01]\n",
      " [ 4.96916389e+01]\n",
      " [ 4.81785774e+01]\n",
      " [ 1.92140789e+01]\n",
      " [ 3.73253784e+01]\n",
      " [ 2.47267723e+01]\n",
      " [ 2.26475773e+01]\n",
      " [ 2.50433235e+01]\n",
      " [ 4.47410889e+01]\n",
      " [ 3.44546890e+01]\n",
      " [ 1.67230778e+01]\n",
      " [ 4.63262367e+01]\n",
      " [ 3.91276321e+01]\n",
      " [ 3.63270607e+01]\n",
      " [ 3.55600433e+01]\n",
      " [ 2.32034855e+01]\n",
      " [ 2.58111248e+01]\n",
      " [ 3.63048973e+01]\n",
      " [ 4.66430664e+01]\n",
      " [ 4.18353577e+01]\n",
      " [ 2.74725533e+01]\n",
      " [ 2.86326008e+01]\n",
      " [ 3.06833935e+01]\n",
      " [ 4.22137375e+01]\n",
      " [ 6.45533371e+01]\n",
      " [ 4.49243240e+01]\n",
      " [ 3.57783203e+01]\n",
      " [ 3.23738708e+01]\n",
      " [ 3.28344574e+01]\n",
      " [ 3.40526848e+01]\n",
      " [ 3.71572609e+01]\n",
      " [ 4.09170189e+01]\n",
      " [ 1.71169739e+02]\n",
      " [ 4.95514832e+01]\n",
      " [ 3.34058113e+01]\n",
      " [ 2.80745831e+01]\n",
      " [ 2.93936348e+01]\n",
      " [ 4.00116386e+01]\n",
      " [ 2.98751659e+01]\n",
      " [ 3.20774231e+01]\n",
      " [ 2.93253746e+01]\n",
      " [ 3.92855377e+01]\n",
      " [ 2.33612099e+01]\n",
      " [ 3.10455074e+01]\n",
      " [ 3.53014755e+01]\n",
      " [ 3.27929115e+01]\n",
      " [ 2.95917110e+01]\n",
      " [ 3.96056595e+01]\n",
      " [ 1.65439510e+01]\n",
      " [ 5.24555855e+01]\n",
      " [ 4.71208229e+01]\n",
      " [ 5.17364655e+01]\n",
      " [ 4.10944786e+01]\n",
      " [ 2.99937210e+01]\n",
      " [ 3.07279911e+01]\n",
      " [ 3.71853714e+01]\n",
      " [ 2.86682816e+01]\n",
      " [ 1.54476807e+02]\n",
      " [ 4.57010231e+01]\n",
      " [ 3.32588882e+01]\n",
      " [ 5.26231270e+01]\n",
      " [ 3.65045967e+01]\n",
      " [ 4.34168091e+01]\n",
      " [ 2.42761440e+01]\n",
      " [ 2.63151283e+01]\n",
      " [ 3.85543671e+01]\n",
      " [ 1.87986359e+02]\n",
      " [ 4.18673973e+01]\n",
      " [ 3.13006229e+01]\n",
      " [ 2.95084381e+01]\n",
      " [ 5.49318848e+01]\n",
      " [ 4.50398331e+01]\n",
      " [ 4.05701408e+01]\n",
      " [ 4.11461716e+01]\n",
      " [ 4.39191399e+01]\n",
      " [ 3.89585152e+01]\n",
      " [ 1.79209976e+02]\n",
      " [ 4.53625107e+01]\n",
      " [ 3.08370380e+01]\n",
      " [ 2.22574463e+01]\n",
      " [ 1.57795887e+01]\n",
      " [ 3.46602478e+01]\n",
      " [ 3.05492516e+01]\n",
      " [ 3.12706337e+01]\n",
      " [ 3.91117630e+01]\n",
      " [ 3.98898354e+01]\n",
      " [ 3.42381783e+01]\n",
      " [ 3.65746040e+01]\n",
      " [ 4.06705437e+01]\n",
      " [ 1.96191483e+01]\n",
      " [ 6.62386551e+01]\n",
      " [ 4.91803093e+01]\n",
      " [ 3.71936340e+01]\n",
      " [ 4.73537025e+01]\n",
      " [ 4.11450424e+01]\n",
      " [ 3.34207077e+01]\n",
      " [ 3.47815437e+01]\n",
      " [ 4.95331039e+01]\n",
      " [ 1.25295647e+02]\n",
      " [ 3.34819260e+01]\n",
      " [ 5.87176208e+01]\n",
      " [ 5.68265572e+01]\n",
      " [ 5.50193298e+02]\n",
      " [ 3.15550327e+01]\n",
      " [ 7.17602005e+01]\n",
      " [ 3.15683422e+01]\n",
      " [ 3.34173393e+01]\n",
      " [ 5.10606651e+01]\n",
      " [ 3.26804314e+01]\n",
      " [ 3.26721458e+01]\n",
      " [ 3.25404015e+01]\n",
      " [ 4.45614204e+01]\n",
      " [ 3.95769386e+01]\n",
      " [ 3.07979984e+01]\n",
      " [ 4.55074158e+01]\n",
      " [ 4.08109474e+01]\n",
      " [ 4.78888512e+01]\n",
      " [ 3.26592331e+01]\n",
      " [ 3.01069183e+01]\n",
      " [ 3.94347229e+01]\n",
      " [ 4.62362213e+01]\n",
      " [ 3.97544746e+01]\n",
      " [ 3.76471596e+01]\n",
      " [ 3.88106766e+01]\n",
      " [ 2.73023796e+01]\n",
      " [ 7.67800522e+01]\n",
      " [ 2.23571854e+01]\n",
      " [ 5.11639923e+02]\n",
      " [ 3.63839149e+01]\n",
      " [ 2.94693775e+01]\n",
      " [ 3.94734306e+01]\n",
      " [ 5.28719482e+01]\n",
      " [ 4.03191719e+01]\n",
      " [ 4.41371727e+01]\n",
      " [ 3.53860870e+02]\n",
      " [ 3.59476395e+01]\n",
      " [-3.89772606e+01]\n",
      " [ 2.85776424e+01]\n",
      " [ 5.14554939e+01]\n",
      " [ 7.54415436e+01]\n",
      " [ 3.38465729e+01]\n",
      " [ 2.91635017e+01]\n",
      " [ 6.09068031e+01]\n",
      " [ 4.66520576e+01]\n",
      " [ 3.62662048e+01]\n",
      " [ 5.40185013e+01]\n",
      " [ 5.17049713e+01]\n",
      " [ 2.34011040e+01]\n",
      " [ 2.82367039e+01]\n",
      " [ 3.35580688e+02]\n",
      " [ 3.85444374e+01]\n",
      " [ 4.36010818e+01]\n",
      " [ 3.91376381e+01]\n",
      " [ 3.78845062e+01]\n",
      " [ 3.25023193e+01]\n",
      " [ 4.60115089e+01]\n",
      " [ 2.69577103e+01]\n",
      " [ 1.68243351e+01]\n",
      " [ 3.33587990e+01]\n",
      " [ 4.07269173e+01]\n",
      " [ 4.10967522e+01]\n",
      " [ 4.17321434e+01]\n",
      " [ 4.42683792e+01]\n",
      " [ 3.77158890e+01]\n",
      " [ 3.00827312e+01]\n",
      " [ 3.67592506e+01]\n",
      " [ 5.86826515e+01]\n",
      " [ 2.75092602e+01]\n",
      " [ 4.60201302e+01]\n",
      " [ 1.48980911e+02]\n",
      " [ 3.73123856e+01]\n",
      " [ 2.08892117e+01]\n",
      " [ 3.62340164e+01]\n",
      " [ 2.33494835e+01]\n",
      " [ 3.68452988e+01]\n",
      " [ 2.56138115e+01]\n",
      " [ 4.96044006e+01]\n",
      " [ 3.20467529e+01]\n",
      " [ 3.59870186e+01]\n",
      " [ 3.27110405e+01]\n",
      " [ 2.71027775e+01]\n",
      " [ 3.57370338e+01]\n",
      " [ 3.13259544e+01]\n",
      " [ 4.11612778e+01]\n",
      " [ 3.90047150e+01]\n",
      " [ 5.61361809e+01]\n",
      " [ 4.23494453e+01]\n",
      " [ 3.09699955e+01]\n",
      " [ 2.29985504e+01]\n",
      " [ 7.20985336e+01]\n",
      " [ 4.44545364e+01]\n",
      " [ 9.19091702e+00]\n",
      " [ 5.40755920e+01]\n",
      " [ 3.82413292e+01]\n",
      " [ 3.12925606e+01]\n",
      " [ 2.35094872e+01]\n",
      " [ 1.98488655e+01]\n",
      " [ 3.60007401e+01]\n",
      " [ 4.75508347e+01]\n",
      " [ 2.86211205e+01]\n",
      " [ 2.78614979e+01]\n",
      " [ 3.58153191e+01]\n",
      " [ 3.52705269e+01]\n",
      " [ 4.17344933e+01]\n",
      " [ 3.84776382e+01]\n",
      " [ 2.80526600e+01]\n",
      " [ 3.63761024e+01]\n",
      " [ 3.18196487e+01]\n",
      " [ 3.48911858e+01]\n",
      " [ 6.28679962e+01]\n",
      " [ 3.21129112e+01]\n",
      " [ 4.75029945e+01]\n",
      " [ 2.85630245e+01]\n",
      " [ 4.25584259e+01]\n",
      " [ 4.41613579e+01]\n",
      " [ 3.13771133e+01]\n",
      " [ 3.42349930e+01]\n",
      " [ 1.37524979e+02]\n",
      " [ 4.69133301e+01]\n",
      " [ 4.87793846e+01]\n",
      " [ 4.52526131e+01]\n",
      " [ 2.92343197e+01]\n",
      " [ 2.71783161e+01]\n",
      " [ 2.21439075e+01]\n",
      " [ 2.73729172e+01]\n",
      " [ 2.91782742e+01]\n",
      " [ 2.63119812e+02]\n",
      " [ 3.09680233e+01]\n",
      " [ 4.76260757e+00]\n",
      " [ 4.05005455e+01]\n",
      " [ 5.93935966e+01]\n",
      " [ 2.28409748e+01]\n",
      " [ 5.51487350e+01]\n",
      " [ 4.86608315e+01]\n",
      " [ 4.05800056e+01]\n",
      " [ 3.32645187e+01]\n",
      " [ 8.28591766e+01]\n",
      " [ 2.01578655e+01]\n",
      " [ 2.75766125e+01]\n",
      " [ 3.80281715e+01]\n",
      " [ 3.77909317e+01]\n",
      " [ 2.87405701e+01]\n",
      " [ 4.03546333e+01]\n",
      " [ 3.36523285e+01]\n",
      " [ 2.99044590e+01]\n",
      " [ 4.83994865e+01]\n",
      " [ 3.20157204e+01]\n",
      " [ 6.58341293e+01]\n",
      " [ 3.59448395e+01]\n",
      " [ 3.42397652e+01]\n",
      " [ 3.14767151e+01]\n",
      " [ 3.07215176e+01]\n",
      " [ 4.08905602e+01]\n",
      " [ 4.63803787e+01]\n",
      " [ 1.61440315e+01]\n",
      " [ 2.77142372e+01]\n",
      " [ 9.17359085e+01]\n",
      " [ 3.35910759e+01]\n",
      " [ 3.14926529e+01]\n",
      " [ 3.68857460e+01]\n",
      " [ 6.15126381e+01]\n",
      " [ 4.53928337e+01]\n",
      " [ 3.19498940e+01]\n",
      " [ 4.27625961e+01]\n",
      " [ 2.65139618e+01]\n",
      " [ 4.12366829e+01]\n",
      " [ 4.76571312e+01]\n",
      " [ 5.98760529e+01]\n",
      " [ 2.93901520e+01]\n",
      " [ 3.40491295e+01]\n",
      " [ 7.73410187e+01]\n",
      " [ 2.60143166e+01]\n",
      " [ 2.71556168e+01]\n",
      " [ 3.16823368e+01]\n",
      " [ 4.58030624e+01]\n",
      " [ 2.79762955e+01]\n",
      " [ 5.85549889e+01]\n",
      " [ 3.18213692e+01]\n",
      " [ 3.49052429e+01]\n",
      " [ 3.39426498e+01]\n",
      " [ 3.28402405e+01]\n",
      " [ 2.77623100e+01]\n",
      " [ 3.04305935e+01]\n",
      " [ 3.46660233e+01]\n",
      " [ 3.15262814e+01]\n",
      " [ 6.91730118e+01]\n",
      " [ 3.06967468e+01]\n",
      " [ 4.10618896e+01]\n",
      " [ 4.59670334e+01]\n",
      " [ 3.60878677e+01]\n",
      " [ 4.14483871e+01]\n",
      " [ 4.90702553e+01]\n",
      " [ 3.48795319e+01]\n",
      " [ 4.69907341e+01]\n",
      " [ 3.21507454e+01]\n",
      " [ 5.37583313e+01]\n",
      " [ 5.02707458e+02]\n",
      " [ 3.37125473e+01]\n",
      " [ 2.78044567e+01]\n",
      " [ 4.65831299e+01]\n",
      " [ 3.54991722e+01]\n",
      " [ 5.95876846e+01]\n",
      " [ 2.64502697e+01]\n",
      " [ 2.89228230e+01]\n",
      " [ 6.82004166e+01]\n",
      " [ 3.70840950e+01]\n",
      " [ 2.86798859e+02]\n",
      " [ 2.19328522e+02]\n",
      " [ 4.38804741e+01]\n",
      " [ 3.27223663e+01]\n",
      " [ 3.66248093e+01]\n",
      " [ 3.16662884e+01]\n",
      " [ 3.97814789e+01]\n",
      " [ 4.36404686e+01]\n",
      " [ 2.46358852e+01]\n",
      " [ 3.68157768e+01]\n",
      " [ 5.07441101e+01]\n",
      " [ 4.21512032e+01]\n",
      " [ 2.82358799e+01]\n",
      " [ 2.21225147e+01]\n",
      " [ 3.95689316e+01]\n",
      " [ 5.61431999e+01]\n",
      " [ 3.80719109e+01]\n",
      " [ 3.51549950e+01]\n",
      " [ 3.26719093e+01]\n",
      " [ 4.29898415e+01]\n",
      " [ 1.98623276e+01]\n",
      " [ 4.80041046e+01]\n",
      " [ 3.18140602e+01]\n",
      " [ 3.42204170e+01]\n",
      " [ 5.93005142e+01]\n",
      " [ 2.66319370e+01]\n",
      " [ 4.54786377e+01]\n",
      " [ 2.54873428e+01]\n",
      " [ 2.03611717e+01]\n",
      " [ 4.26267014e+01]\n",
      " [ 4.84556732e+01]\n",
      " [ 3.94838104e+01]\n",
      " [ 3.28111038e+01]\n",
      " [ 3.44155998e+01]\n",
      " [ 2.96533089e+01]\n",
      " [ 5.09313240e+01]\n",
      " [ 5.23144569e+01]\n",
      " [ 2.82515411e+01]\n",
      " [ 3.65823097e+01]\n",
      " [ 3.95845451e+01]\n",
      " [ 2.39322605e+01]\n",
      " [ 3.41779785e+01]\n",
      " [ 8.83931427e+01]\n",
      " [ 4.01927338e+01]\n",
      " [ 3.37373886e+01]\n",
      " [ 4.22172966e+01]\n",
      " [ 4.06828232e+01]\n",
      " [ 3.15613632e+01]\n",
      " [ 4.68966255e+01]\n",
      " [ 4.82874451e+01]\n",
      " [ 2.28938999e+01]\n",
      " [-1.19301128e+01]\n",
      " [ 2.95972347e+01]\n",
      " [ 4.35846825e+01]\n",
      " [ 4.09930382e+01]\n",
      " [ 3.27169151e+01]\n",
      " [ 4.11810913e+01]\n",
      " [ 2.36224670e+01]\n",
      " [ 1.91909012e+02]\n",
      " [ 4.07440758e+01]\n",
      " [ 3.73271599e+01]\n",
      " [ 4.90493927e+01]\n",
      " [ 4.38982506e+01]\n",
      " [ 3.65696526e+01]\n",
      " [ 4.37135887e+01]\n",
      " [ 8.26458817e+01]\n",
      " [ 3.70244560e+01]\n",
      " [ 2.72530613e+01]\n",
      " [ 2.97378464e+01]\n",
      " [ 3.68898811e+01]\n",
      " [ 3.58341370e+01]\n",
      " [ 3.58131905e+01]\n",
      " [ 4.59498215e+01]\n",
      " [ 2.60962353e+01]\n",
      " [ 8.40844750e-01]\n",
      " [ 3.56063614e+01]\n",
      " [ 8.29419174e+01]\n",
      " [ 3.99951691e+02]\n",
      " [ 3.38623428e+01]\n",
      " [ 2.67210827e+01]\n",
      " [ 3.39702492e+01]\n",
      " [ 3.90740585e+01]\n",
      " [ 2.26026020e+01]\n",
      " [ 3.84808731e+01]\n",
      " [ 3.26218147e+01]\n",
      " [ 4.33228912e+01]\n",
      " [ 3.07353172e+01]\n",
      " [ 2.74486809e+01]\n",
      " [ 3.30175896e+01]\n",
      " [ 2.41633739e+01]\n",
      " [ 2.42616558e+01]\n",
      " [ 4.78855972e+01]\n",
      " [ 3.26165504e+01]\n",
      " [ 2.82022057e+01]\n",
      " [ 2.96012917e+01]\n",
      " [ 3.85946426e+01]\n",
      " [ 3.82200279e+01]\n",
      " [ 5.00921555e+01]\n",
      " [ 7.35303574e+01]\n",
      " [ 1.43827047e+01]\n",
      " [ 3.13280373e+01]\n",
      " [ 3.00351257e+01]\n",
      " [ 3.24184341e+01]\n",
      " [ 4.58500748e+01]\n",
      " [ 4.05281258e+01]\n",
      " [ 3.48776741e+01]\n",
      " [ 2.43096313e+01]\n",
      " [ 3.94165459e+01]\n",
      " [ 3.92748375e+01]\n",
      " [ 4.23692513e+01]\n",
      " [ 2.71581497e+01]\n",
      " [ 4.72906952e+01]\n",
      " [ 4.61543922e+01]\n",
      " [ 4.12924843e+01]\n",
      " [ 3.93157883e+01]\n",
      " [ 3.67005882e+01]\n",
      " [ 6.18097191e+01]\n",
      " [ 3.21829910e+01]\n",
      " [ 3.89312553e+01]\n",
      " [ 3.88460388e+01]\n",
      " [ 3.96851616e+01]\n",
      " [ 4.03670998e+01]\n",
      " [ 4.41945572e+01]\n",
      " [ 3.85041924e+01]\n",
      " [ 3.84423218e+01]\n",
      " [ 3.62145119e+01]\n",
      " [ 3.37299271e+01]\n",
      " [ 3.01926823e+01]\n",
      " [ 3.16730671e+01]\n",
      " [ 3.29457932e+01]\n",
      " [ 2.76441002e+01]\n",
      " [ 8.68274307e+01]\n",
      " [ 3.10558472e+01]\n",
      " [ 3.52510529e+01]\n",
      " [ 3.59075279e+01]\n",
      " [ 3.94475288e+01]\n",
      " [ 3.65381889e+01]\n",
      " [ 3.95998688e+01]\n",
      " [ 4.54546127e+01]\n",
      " [ 3.74546356e+01]\n",
      " [ 3.64020348e+01]\n",
      " [ 3.60143127e+01]\n",
      " [ 4.11644402e+01]\n",
      " [ 4.72821426e+01]\n",
      " [ 5.49140778e+01]\n",
      " [ 3.09498863e+01]\n",
      " [ 2.08717480e+01]\n",
      " [ 3.63046455e+01]\n",
      " [ 4.70117836e+01]\n",
      " [ 2.70047035e+01]\n",
      " [ 4.04235687e+01]\n",
      " [ 1.61782867e+02]\n",
      " [ 3.83786545e+01]\n",
      " [ 3.05911007e+01]\n",
      " [ 3.67402916e+01]\n",
      " [ 3.22307663e+01]\n",
      " [ 4.28722305e+01]\n",
      " [ 4.67964287e+01]\n",
      " [ 3.75741997e+01]\n",
      " [ 9.91001816e+01]\n",
      " [ 3.26847382e+01]\n",
      " [ 3.75731201e+01]\n",
      " [ 3.88524170e+01]\n",
      " [ 4.56593513e+01]\n",
      " [ 8.42642212e+01]\n",
      " [ 4.12340469e+01]\n",
      " [ 3.07997990e+01]\n",
      " [ 5.79038239e+01]\n",
      " [ 4.35482979e+01]\n",
      " [ 1.87733250e+01]\n",
      " [ 1.42162524e+03]\n",
      " [ 3.61116142e+01]\n",
      " [ 4.87481308e+01]\n",
      " [ 7.20232697e+01]\n",
      " [ 3.82461433e+01]\n",
      " [ 8.25343628e+01]\n",
      " [ 2.78184452e+01]\n",
      " [ 4.52463188e+01]\n",
      " [ 3.15692711e+01]\n",
      " [ 5.64442139e+01]\n",
      " [ 3.14511375e+01]\n",
      " [ 3.68769417e+01]\n",
      " [ 2.82401505e+01]\n",
      " [ 3.78595314e+01]\n",
      " [ 3.18127899e+01]\n",
      " [ 2.73529034e+01]\n",
      " [ 3.09459000e+01]\n",
      " [ 3.10002747e+01]\n",
      " [ 3.76048355e+01]\n",
      " [ 2.67219715e+01]\n",
      " [ 3.38194618e+01]\n",
      " [ 3.52450676e+01]\n",
      " [ 3.05963707e+01]\n",
      " [ 4.06102600e+01]\n",
      " [ 8.99251251e+01]\n",
      " [ 2.80646172e+01]\n",
      " [ 3.16614552e+01]\n",
      " [ 3.72170753e+01]\n",
      " [ 3.53545456e+01]\n",
      " [-1.44339633e+00]\n",
      " [ 4.09191589e+01]\n",
      " [ 3.19363041e+01]\n",
      " [ 2.77377224e+01]\n",
      " [ 2.69734383e+01]\n",
      " [ 4.02640266e+01]\n",
      " [ 3.96585617e+01]\n",
      " [ 3.03154259e+01]\n",
      " [ 2.95834141e+01]\n",
      " [ 5.15001335e+01]\n",
      " [ 4.76670532e+01]\n",
      " [ 2.29629974e+01]\n",
      " [ 3.16398392e+01]\n",
      " [ 2.73446026e+01]\n",
      " [ 2.39275665e+01]\n",
      " [ 3.40117722e+01]\n",
      " [ 3.22987480e+01]\n",
      " [ 8.10369682e+00]\n",
      " [ 3.63903885e+01]\n",
      " [ 5.35827599e+01]\n",
      " [ 3.87083282e+01]\n",
      " [ 3.01357155e+01]\n",
      " [ 4.34222908e+01]\n",
      " [ 4.01726151e+01]\n",
      " [ 2.72389927e+01]\n",
      " [ 2.26353931e+01]\n",
      " [ 3.24227104e+01]\n",
      " [ 3.66860733e+01]\n",
      " [ 4.54888992e+01]\n",
      " [ 5.51060753e+01]\n",
      " [ 3.05810947e+01]\n",
      " [ 3.19373531e+01]\n",
      " [ 3.96191101e+01]\n",
      " [ 4.17133789e+01]\n",
      " [ 5.06897316e+01]]\n"
     ]
    }
   ],
   "source": [
    "print(age_true)\n",
    "print(age_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deviance Score for age: -16.175936770991388\n"
     ]
    }
   ],
   "source": [
    "print('Deviance Score for age:', explained_variance_score(age_true, age_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
