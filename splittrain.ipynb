{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder_name = 'TrainFiles/Splits/FivePercentSplit'\n",
    "testset_folder_name_WM = 'TestFiles/WM'\n",
    "testset_folder_name_WW = 'TestFiles/WW'\n",
    "testset_folder_name_BM = 'TestFiles/BM'\n",
    "testset_folder_name_BW = 'TestFiles/BW'\n",
    "\n",
    "TRAIN_TEST_SPLIT = 0.7\n",
    "IM_WIDTH = IM_HEIGHT = 198\n",
    "\n",
    "dataset_dict = {\n",
    "    'race_id': {\n",
    "        0: 'white', \n",
    "        1: 'black', \n",
    "        2: 'asian', \n",
    "        3: 'indian', \n",
    "        4: 'others'\n",
    "    },\n",
    "    'gender_id': {\n",
    "        0: 'male',\n",
    "        1: 'female'\n",
    "    }\n",
    "}\n",
    "\n",
    "dataset_dict['gender_alias'] = dict((g, i) for i, g in dataset_dict['gender_id'].items())\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_dataset(dataset_path, ext='jpg'):\n",
    "    \"\"\"\n",
    "    Used to extract information about our dataset. It does iterate over all images and return a DataFrame with\n",
    "    the data (age, gender and sex) of all files.\n",
    "    \"\"\"\n",
    "    def parse_info_from_file(path):\n",
    "        \"\"\"\n",
    "        Parse information from a single file\n",
    "        \"\"\"\n",
    "        try:\n",
    "            filename = os.path.split(path)[1]\n",
    "            filename = os.path.splitext(filename)[0]\n",
    "            age, gender, race, _ = filename.split('_')\n",
    "\n",
    "            return dataset_dict['gender_id'][int(gender)]\n",
    "        except Exception as ex:\n",
    "            return None, None, None\n",
    "        \n",
    "    files = glob.glob(os.path.join(dataset_path, \"*.%s\" % ext))\n",
    "    random.shuffle(files)\n",
    "    \n",
    "    records = []\n",
    "    for file in files:\n",
    "        info = parse_info_from_file(file)\n",
    "        records.append(info)\n",
    "        \n",
    "    df = pd.DataFrame(records)\n",
    "    df['file'] = files\n",
    "    df.columns = ['gender', 'file']\n",
    "    df = df.dropna()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = parse_dataset(dataset_folder_name)\n",
    "testset_WM = parse_dataset(testset_folder_name_WM)\n",
    "testset_WW = parse_dataset(testset_folder_name_WW)\n",
    "testset_BM = parse_dataset(testset_folder_name_BM)\n",
    "testset_BW = parse_dataset(testset_folder_name_BW)\n",
    "testset_WM.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Makes Data Generator For Trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "class UtkFaceDataGenerator():\n",
    "    \"\"\"\n",
    "    Data generator for the UTKFace dataset. This class should be used when training our Keras multi-output model.\n",
    "    \"\"\"\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        \n",
    "    def generate_split_indexes(self, SPLIT):\n",
    "        p = np.random.permutation(len(self.df))\n",
    "        train_up_to = int(len(self.df) * SPLIT)\n",
    "        train_idx = p[:train_up_to]\n",
    "        test_idx = p[train_up_to:]\n",
    "\n",
    "        train_up_to = int(train_up_to * SPLIT)\n",
    "        train_idx, valid_idx = train_idx[:train_up_to], train_idx[train_up_to:]\n",
    "        \n",
    "        # converts alias to id\n",
    "        self.df['gender_id'] = self.df['gender'].map(lambda gender: dataset_dict['gender_alias'][gender])\n",
    "        \n",
    "        return train_idx, valid_idx, test_idx\n",
    "    \n",
    "    def preprocess_image(self, img_path):\n",
    "        \"\"\"\n",
    "        Used to perform some minor preprocessing on the image before inputting into the network.\n",
    "        \"\"\"\n",
    "        im = Image.open(img_path)\n",
    "        im = im.resize((IM_WIDTH, IM_HEIGHT))\n",
    "        im = np.array(im) / 255.0\n",
    "        \n",
    "        return im\n",
    "        \n",
    "    def generate_images(self, image_idx, is_training, batch_size=16):\n",
    "        \"\"\"\n",
    "        Used to generate a batch with images when training/testing/validating our Keras model.\n",
    "        \"\"\"\n",
    "        \n",
    "        # arrays to store our batched data\n",
    "        images, genders = [], []\n",
    "        while True:\n",
    "            for idx in image_idx:\n",
    "                person = self.df.iloc[idx]\n",
    "                \n",
    "                gender = person['gender_id']\n",
    "                file = person['file']\n",
    "                \n",
    "                im = self.preprocess_image(file)\n",
    "                genders.append(to_categorical(gender, len(dataset_dict['gender_id'])))\n",
    "                images.append(im)\n",
    "                \n",
    "                # yielding condition\n",
    "                if len(images) >= batch_size:\n",
    "                    yield np.array(images), [np.array(genders)]\n",
    "                    images, genders = [], []\n",
    "                    \n",
    "            if not is_training:\n",
    "                break\n",
    "                \n",
    "data_generator = UtkFaceDataGenerator(df)\n",
    "train_idx, valid_idx, test_idx = data_generator.generate_split_indexes(TRAIN_TEST_SPLIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generator TestSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DATA_SPLIT = 0\n",
    "#WM\n",
    "test_data_generator_WM = UtkFaceDataGenerator(testset_WM)\n",
    "train_idx_test_WM, valid_idx_test_WM, test_idx_test_WM = test_data_generator_WM.generate_split_indexes(TEST_DATA_SPLIT)\n",
    "#WW\n",
    "test_data_generator_WW = UtkFaceDataGenerator(testset_WW)\n",
    "train_idx_test_WW, valid_idx_test_WW, test_idx_test_WW = test_data_generator_WW.generate_split_indexes(TEST_DATA_SPLIT)\n",
    "#BM\n",
    "test_data_generator_BM = UtkFaceDataGenerator(testset_BM)\n",
    "train_idx_test_BM, valid_idx_test_BM, test_idx_test_BM = test_data_generator_BM.generate_split_indexes(TEST_DATA_SPLIT)\n",
    "#BW\n",
    "test_data_generator_BW = UtkFaceDataGenerator(testset_BW)\n",
    "train_idx_test_BW, valid_idx_test_BW, test_idx_test_BW = test_data_generator_BW.generate_split_indexes(TEST_DATA_SPLIT)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Making Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Input\n",
    "import tensorflow as tf\n",
    "\n",
    "class UtkMultiOutputModel():\n",
    "    \"\"\"\n",
    "    Used to generate our multi-output model. This CNN contains three branches, one for age, other for \n",
    "    sex and another for race. Each branch contains a sequence of Convolutional Layers that is defined\n",
    "    on the make_default_hidden_layers method.\n",
    "    \"\"\"\n",
    "    def make_default_hidden_layers(self, inputs):\n",
    "        \"\"\"\n",
    "        Used to generate a default set of hidden layers. The structure used in this network is defined as:\n",
    "        \n",
    "        Conv2D -> BatchNormalization -> Pooling -> Dropout\n",
    "        \"\"\"\n",
    "        x = Conv2D(16, (3, 3), padding=\"same\")(inputs)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=-1)(x)\n",
    "        x = MaxPooling2D(pool_size=(3, 3))(x)\n",
    "        x = Dropout(0.25)(x)\n",
    "\n",
    "        x = Conv2D(32, (3, 3), padding=\"same\")(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=-1)(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "        x = Dropout(0.25)(x)\n",
    "\n",
    "        x = Conv2D(32, (3, 3), padding=\"same\")(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=-1)(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "        x = Dropout(0.25)(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def build_race_branch(self, inputs, num_races):\n",
    "        \"\"\"\n",
    "        Used to build the race branch of our face recognition network.\n",
    "        This branch is composed of three Conv -> BN -> Pool -> Dropout blocks, \n",
    "        followed by the Dense output layer.\n",
    "        \"\"\"\n",
    "        x = self.make_default_hidden_layers(inputs)\n",
    "\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(128)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(num_races)(x)\n",
    "        x = Activation(\"softmax\", name=\"race_output\")(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def build_gender_branch(self, inputs, num_genders=2):\n",
    "        \"\"\"\n",
    "        Used to build the gender branch of our face recognition network.\n",
    "        This branch is composed of three Conv -> BN -> Pool -> Dropout blocks, \n",
    "        followed by the Dense output layer.\n",
    "        \"\"\"\n",
    "        x = Lambda(lambda c: tf.image.rgb_to_grayscale(c))(inputs)\n",
    "\n",
    "        x = self.make_default_hidden_layers(inputs)\n",
    "\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(128)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(num_genders)(x)\n",
    "        x = Activation(\"sigmoid\", name=\"gender_output\")(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def build_age_branch(self, inputs):   \n",
    "        \"\"\"\n",
    "        Used to build the age branch of our face recognition network.\n",
    "        This branch is composed of three Conv -> BN -> Pool -> Dropout blocks, \n",
    "        followed by the Dense output layer.\n",
    "\n",
    "        \"\"\"\n",
    "        x = self.make_default_hidden_layers(inputs)\n",
    "\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(128)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(1)(x)\n",
    "        x = Activation(\"linear\", name=\"age_output\")(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def assemble_full_model(self, width, height):\n",
    "        \"\"\"\n",
    "        Used to assemble our multi-output model CNN.\n",
    "        \"\"\"\n",
    "        input_shape = (height, width, 3)\n",
    "\n",
    "        inputs = Input(shape=input_shape)\n",
    "\n",
    "        gender_branch = self.build_gender_branch(inputs)\n",
    "\n",
    "        model = Model(inputs=inputs,\n",
    "                     outputs = [gender_branch],\n",
    "                     name=\"face_net\")\n",
    "\n",
    "        return model\n",
    "    \n",
    "model = UtkMultiOutputModel().assemble_full_model(IM_WIDTH, IM_HEIGHT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''%matplotlib inline\n",
    "\n",
    "from keras.utils import plot_model\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plot_model(model, to_file='model.png')\n",
    "img = mpimg.imread('model.png')\n",
    "\n",
    "plt.figure(figsize=(40, 30))\n",
    "plt.imshow(img)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "init_lr = 1e-4\n",
    "epochs = 100\n",
    "\n",
    "opt = Adam(lr=init_lr, decay=init_lr / epochs)\n",
    "\n",
    "model.compile(optimizer=opt, \n",
    "              loss={\n",
    "                  'gender_output': 'binary_crossentropy'},\n",
    "              loss_weights={ \n",
    "                  'gender_output': 0.1},\n",
    "              metrics={\n",
    "                  'gender_output': 'accuracy'})\n",
    "\n",
    "valid_batch_size = 32\n",
    "print(len(valid_idx))\n",
    "print(len(valid_idx)//valid_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's train our model with a batch size of 32 for both valid and train sets. We will be using a ModelCheckpoint callback in order to save the model on disk at the end of each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "batch_size = 32\n",
    "valid_batch_size = 32\n",
    "train_gen = data_generator.generate_images(train_idx, is_training=True, batch_size=batch_size)\n",
    "valid_gen = data_generator.generate_images(valid_idx, is_training=True, batch_size=valid_batch_size)\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\"./model_checkpoint\", monitor='val_loss')\n",
    "]\n",
    "\n",
    "history = model.fit_generator(train_gen,\n",
    "                    steps_per_epoch=len(train_idx)//batch_size,\n",
    "                    epochs=epochs,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=valid_gen,\n",
    "                    validation_steps=len(valid_idx)//valid_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "plt.clf()\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(\n",
    "                    y=history.history['gender_output_acc'],\n",
    "                    name='Train'))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "                    y=history.history['val_gender_output_acc'],\n",
    "                    name='Valid'))\n",
    "\n",
    "\n",
    "fig.update_layout(height=450, \n",
    "                  width=600,\n",
    "                  title='Accuracy for gender feature',\n",
    "                  xaxis_title='Epoch',\n",
    "                  yaxis_title='Accuracy')\n",
    "\n",
    "fig.write_html('acc_gender.html', include_plotlyjs='cdn')\n",
    "\n",
    "fig.show()\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scattergl(\n",
    "                    y=history.history['loss'],\n",
    "                    name='Train'))\n",
    "\n",
    "fig.add_trace(go.Scattergl(\n",
    "                    y=history.history['val_loss'],\n",
    "                    name='Valid'))\n",
    "\n",
    "\n",
    "fig.update_layout(height=450, \n",
    "                  width=600,\n",
    "                  title='Overall loss',\n",
    "                  xaxis_title='Epoch',\n",
    "                  yaxis_title='Loss')\n",
    "\n",
    "fig.write_html('overall_loss.html', include_plotlyjs='cdn')\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "test_batch_size = 128\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### White Men"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_generator = test_data_generator_WM.generate_images(test_idx_test_WM, is_training=False, batch_size=test_batch_size)\n",
    "gender_pred = model.predict_generator(test_generator, steps=len(test_idx_test_WM)//test_batch_size)\n",
    "\n",
    "\n",
    "\n",
    "test_generator = test_data_generator_WM.generate_images(test_idx_test_WM, is_training=False, batch_size=test_batch_size)\n",
    "samples = 0\n",
    "images, gender_true = [], []\n",
    "for test_batch in test_generator:\n",
    "    image = test_batch[0]\n",
    "    labels = test_batch[1]\n",
    "    \n",
    "    images.extend(image)\n",
    "    gender_true.extend(labels[0])\n",
    "\n",
    "gender_true = np.array(gender_true)\n",
    "\n",
    "gender_true =  gender_true.argmax(axis=-1)\n",
    "gender_pred =  gender_pred.argmax(axis=-1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "cr_gender = classification_report(gender_true, gender_pred, target_names=dataset_dict['gender_alias'].keys())\n",
    "print(cr_gender)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### White Women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = test_data_generator_WW.generate_images(test_idx_test_WW, is_training=False, batch_size=test_batch_size)\n",
    "gender_pred = model.predict_generator(test_generator, steps=len(test_idx_test_WW)//test_batch_size)\n",
    "\n",
    "\n",
    "\n",
    "test_generator = test_data_generator_WW.generate_images(test_idx_test_WW, is_training=False, batch_size=test_batch_size)\n",
    "samples = 0\n",
    "images, gender_true = [], []\n",
    "for test_batch in test_generator:\n",
    "    image = test_batch[0]\n",
    "    labels = test_batch[1]\n",
    "    \n",
    "    images.extend(image)\n",
    "    gender_true.extend(labels[0])\n",
    "    \n",
    "gender_true = np.array(gender_true)\n",
    "\n",
    "gender_true = gender_true.argmax(axis=-1)\n",
    "gender_pred = gender_pred.argmax(axis=-1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "cr_gender = classification_report(gender_true, gender_pred, target_names=dataset_dict['gender_alias'].keys())\n",
    "print(cr_gender)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Black Men"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = test_data_generator_BM.generate_images(test_idx_test_BM, is_training=False, batch_size=test_batch_size)\n",
    "gender_pred = model.predict_generator(test_generator, steps=len(test_idx_test_BM)//test_batch_size)\n",
    "\n",
    "\n",
    "\n",
    "test_generator = test_data_generator_BM.generate_images(test_idx_test_BM, is_training=False, batch_size=test_batch_size)\n",
    "samples = 0\n",
    "images, gender_true = [], []\n",
    "for test_batch in test_generator:\n",
    "    image = test_batch[0]\n",
    "    labels = test_batch[1]\n",
    "    \n",
    "    images.extend(image)\n",
    "    gender_true.extend(labels[0])\n",
    "    \n",
    "gender_true = np.array(gender_true)\n",
    "\n",
    "gender_true = gender_true.argmax(axis=-1)\n",
    "gender_pred = gender_pred.argmax(axis=-1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "cr_gender = classification_report(gender_true, gender_pred, target_names=dataset_dict['gender_alias'].keys())\n",
    "print(cr_gender)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Black Women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = test_data_generator_BW.generate_images(test_idx_test_BW, is_training=False, batch_size=test_batch_size)\n",
    "gender_pred = model.predict_generator(test_generator, steps=len(test_idx_test_BW)//test_batch_size)\n",
    "\n",
    "\n",
    "\n",
    "test_generator = test_data_generator_BW.generate_images(test_idx_test_BW, is_training=False, batch_size=test_batch_size)\n",
    "samples = 0\n",
    "images, gender_true = [], []\n",
    "for test_batch in test_generator:\n",
    "    image = test_batch[0]\n",
    "    labels = test_batch[1]\n",
    "    \n",
    "    images.extend(image)\n",
    "    gender_true.extend(labels[0])\n",
    "    \n",
    "gender_true = np.array(gender_true)\n",
    "\n",
    "gender_true = gender_true.argmax(axis=-1)\n",
    "gender_pred = gender_pred.argmax(axis=-1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "cr_gender = classification_report(gender_true, gender_pred, target_names=dataset_dict['gender_alias'].keys())\n",
    "print(cr_gender)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import math\n",
    "n = 16\n",
    "random_indices = np.random.permutation(n)\n",
    "n_cols = 4\n",
    "n_rows = math.ceil(n / n_cols)\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 17))\n",
    "for i, img_idx in enumerate(random_indices):\n",
    "    ax = axes.flat[i]\n",
    "    ax.imshow(images[img_idx])\n",
    "    \n",
    "    cur_age_pred = age_pred[img_idx]\n",
    "    cur_age_true = age_true[img_idx]\n",
    "    \n",
    "    cur_gender_pred = gender_pred[img_idx]\n",
    "    cur_gender_true = gender_true[img_idx]\n",
    "    \n",
    "    cur_race_pred = race_pred[img_idx]\n",
    "    cur_race_true = race_true[img_idx]\n",
    "    \n",
    "    age_threshold = 10\n",
    "    if cur_gender_pred == cur_gender_true and cur_race_pred == cur_race_true and abs(cur_age_pred - cur_age_true) <= age_threshold:\n",
    "        ax.xaxis.label.set_color('green')\n",
    "    elif cur_gender_pred != cur_gender_true and cur_race_pred != cur_race_true and abs(cur_age_pred - cur_age_true) > age_threshold:\n",
    "        ax.xaxis.label.set_color('red')\n",
    "    \n",
    "    ax.set_xlabel('a: {}, g: {}, r: {}'.format(int(age_pred[img_idx]),\n",
    "                            dataset_dict['gender_id'][gender_pred[img_idx]],\n",
    "                               dataset_dict['race_id'][race_pred[img_idx]]))\n",
    "    \n",
    "    ax.set_title('a: {}, g: {}, r: {}'.format(int(age_true[img_idx]),\n",
    "                            dataset_dict['gender_id'][gender_true[img_idx]],\n",
    "                               dataset_dict['race_id'][race_true[img_idx]]))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig('preds.png')\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}